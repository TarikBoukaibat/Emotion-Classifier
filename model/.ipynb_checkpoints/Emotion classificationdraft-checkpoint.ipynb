{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e9740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228d6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv',encoding = \"ISO-8859-1\",names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5559f697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52917c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['ids', 'date','user','flag'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6aef5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d2cd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50bd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = '((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*'\n",
    "# Convert to Lower\n",
    "def to_lower(tweet):\n",
    "    tweets = [word.lower() for word in tweet]\n",
    "    return tweets\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# drop stop words\n",
    "def drop_stop_words(tweets):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = list(string.punctuation)\n",
    "    stop_words.update(punctuation)\n",
    "    tweets     = [' '.join(word for word in word_tokenize(tweet) if word not in stop_words) for tweet in tweets]\n",
    "    return tweets\n",
    "\n",
    "# Drop Qoute\n",
    "def Drop_Qoute(tweets):\n",
    "#     tweets = [re.sub('^&(\\w)+;','',tweet) for tweet in tweets]\n",
    "    tweets = [' '.join([re.sub('^&(\\w)+;',' && ',tw) for tw in tweet.split()]) for tweet in tweets] \n",
    "\n",
    "    return tweets\n",
    "\n",
    "# Drop Reetweet\n",
    "def drop_retweet(tweets):\n",
    "    # drop retweet name\n",
    "    tweets = [' '.join([re.sub('^@(\\w)+',' ',tw) for tw in tweet.split()]) for tweet in tweets] \n",
    "    \n",
    "    return tweets\n",
    "\n",
    "def drop_links(tweets):\n",
    "    # Drop URL from text\n",
    "    tweets = [' '.join([re.sub(url,' ',tw) for tw in tweet.split()]) for tweet in tweets] \n",
    "#     tweets = [' '.join([re.sub('^http?:\\/\\/.*[\\r\\n]*',' ',tw) for tw in tweet.split()]) for tweet in tweets] \n",
    "\n",
    "    return tweets\n",
    "\n",
    "def clean_spaces(tweets):\n",
    "    tweets = [\" \".join(tweet.split()) for tweet in tweets]\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def stem_tweets(tweets):\n",
    "    pr  =PorterStemmer() \n",
    "    tweets = [' '.join(pr.stem(word) for word in tweet.split()   ) for tweet in tweets]\n",
    "    return tweets\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def lemtize_tweets(tweets):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    tweets = [' '.join(lemmatizer.lemmatize(word) for word in tweet.split()   ) for tweet in tweets]\n",
    "\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e66dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all(text):\n",
    "    # Convert Text To Lower \n",
    "    text = to_lower(text)\n",
    "\n",
    "    # Drop Retweets User Name\n",
    "    text = drop_retweet(text)\n",
    "\n",
    "    # Drop Links From Tweets\n",
    "    text = drop_links(text)\n",
    "\n",
    "    # Drop HTML tag From Tweets\n",
    "    text = Drop_Qoute(text)\n",
    "\n",
    "    # Drop Stop Words \n",
    "    text = drop_stop_words(text)\n",
    "    \n",
    "    # lematize Words\n",
    "    text = lemtize_tweets(text)\n",
    "    # Clean MUlit Spaces\n",
    "    text = clean_spaces(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "595370e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_on_sample(sample_size,pipeline,model):\n",
    "    # Take Sample\n",
    "    sample = df.sample(sample_size).copy()\n",
    "    \n",
    "    x = sample['text'].copy()\n",
    "    y = sample['target'].copy()\n",
    "    \n",
    "    x_train , x_test , y_train , y_test = train_test_split\\\n",
    "    (x,y,test_size=0.2,random_state=42)\n",
    "    my_pipe = Pipeline(pipeline)\n",
    "    my_pipe.fit(x_train,y_train)\n",
    "    y_hat = my_pipe.predict(x_test)\n",
    "    print(classification_report(y_test,y_hat))\n",
    "\n",
    "    \n",
    "    del  x_train , x_test , y_train , y_test ,x,y ,y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b5ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "to_lower_pipe = FunctionTransformer(to_lower)\n",
    "\n",
    "drop_retweet_pipe = FunctionTransformer(drop_retweet)\n",
    "\n",
    "drop_links_pipe = FunctionTransformer(drop_links)\n",
    "\n",
    "Drop_Qoute_pipe = FunctionTransformer(Drop_Qoute)\n",
    "\n",
    "drop_stop_words_pipe = FunctionTransformer(drop_stop_words)\n",
    "\n",
    "\n",
    "clean_spaces_pipe = FunctionTransformer(clean_spaces)\n",
    "\n",
    "stem_tweets_pipe = FunctionTransformer(stem_tweets)\n",
    "\n",
    "lemtize_tweets_pipe = FunctionTransformer(lemtize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07cb60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.73       154\n",
      "           4       0.72      0.66      0.69       146\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.71      0.71      0.71       300\n",
      "weighted avg       0.71      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  create model\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re \n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "lr = LogisticRegression()\n",
    "# list of function for pipeline\n",
    "lr_pipe = [\n",
    "    ('lower',to_lower_pipe),\n",
    "    ('retweet',drop_retweet_pipe),\n",
    "    ('links',drop_links_pipe),\n",
    "    ('lematization',lemtize_tweets_pipe),\n",
    "    ('spaces',clean_spaces_pipe),\n",
    "    ('counts',TfidfVectorizer(use_idf=True,ngram_range=(1,2))),\n",
    "    ('model',lr)          \n",
    "]\n",
    "# Train and Test Evaluate\n",
    "Test_on_sample(1500,lr_pipe,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21527fb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2132a220a582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) \n",
    "\n",
    "Test_on_sample(1500,lr_pipe,classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67782d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(50000, 16, input_length=35),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "Test_on_sample(1500,lr_pipe,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020125c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
